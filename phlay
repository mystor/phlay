#!/usr/bin/env python3

__version__ = '0.1.4'

import sys
import os
import re
import json
import curses
import base64
import socket
import difflib
import mimetypes
import textwrap
import shlex
import subprocess

from http.client import HTTPSConnection
from urllib.parse import urlencode, urlparse
from argparse import ArgumentParser
from tempfile import TemporaryDirectory
from collections import namedtuple
from pathlib import Path
from enum import Enum


NULL_SHA1 = '0' * 40


def run(*args, binary=False, **kwargs):
    out = subprocess.check_output(args, **kwargs)
    if binary:
        return out
    return out.decode(errors='replace').rstrip()


def http(host, path, data=None, binary=False):
    conn = HTTPSConnection(host)
    if data:
        conn.request("POST", path, body=urlencode(data))
    else:
        conn.request("GET", path)
    if binary:
        return conn.getresponse().read()
    return json.load(conn.getresponse())


def onceprop(func):
    cache = '_cached_' + func.__name__
    def wrap(self):
        try:
            return getattr(self, cache)
        except AttributeError:
            setattr(self, cache, func(self))
            return getattr(self, cache)
    return property(wrap)


class Style:
    """ANSI color helper"""

    class Wrap(str):
        def __call__(self, s):
            if self == '':
                return str(s)
            return self + str(s) + curses.tparm(curses.tigetstr('sgr0')).decode()

    def __init__(self, color):
        isatty = sys.stdout.isatty() and os.environ.get('TERM') != 'dumb'
        self.styled = color == 'always' or (color == 'auto' and isatty)
        if self.styled:
            curses.setupterm()
            self._setf = curses.tigetstr('setaf') or curses.tigetstr('setf')

    def __getattr__(self, name):
        if not self.styled:
            return self.Wrap('')
        if '_' in name:
            return self.Wrap(''.join(getattr(self, n) for n in name.split('_')))
        call = [curses.tigetstr(name)]
        if name in 'black blue cyan green magenta red white yellow'.split():
            call = [self._setf, getattr(curses, 'COLOR_' + name.upper())]
        return self.Wrap(curses.tparm(*call).decode())


class UserError(Exception):
    pass


def fatal(msg):
    raise UserError(msg)


class Conduit:
    @classmethod
    def init(cls, arcrc_path):
        # Load the global and local Arcanist configuration
        cls.top = Path(run('git', 'rev-parse', '--show-toplevel'))
        with open(cls.top / '.arcconfig') as f:
            arcconfig = json.load(f)

        # Load the URL from the local arcconfig
        cls.url = urlparse(arcconfig['phabricator.uri'])
        if cls.url.scheme != 'https':
            raise UserError('Only HTTPS scheme phabricator.uri are supported')

        # Find our authentication token
        arcrc_path = Path(arcrc_path).expanduser()
        arcrc = {}
        try:
            with open(arcrc_path) as f:
                arcrc = json.load(f)

            cls.token = next(data['token'] for url, data in arcrc['hosts'].items()
                             if urlparse(url).netloc == cls.url.netloc)
        except (IOError, StopIteration):
            cls.token = input(textwrap.dedent(f"""\
                LOGIN TO PHABRICATOR

                Open this page in your browser, and login if necessary:
                https://{cls.url.netloc}/conduit/login

                API Token from that page: """)).strip()

            # Double-check the token works
            cls.do('user.whoami')

            # Update our arcrc
            api_uri = f"https://{cls.url.netloc}/api/"
            arcrc['hosts'] = arcrc.get('hosts', {})
            arcrc['hosts'][api_uri] = arcrc['hosts'].get(api_uri, {})
            arcrc['hosts'][api_uri]['token'] = cls.token
            with open(arcrc_path, 'w') as f:
                json.dump(arcrc, f, indent=2)

        # Connect to Conduit to determine our repository's PHID
        callsign = arcconfig['repository.callsign']
        cls.repository = (cls.lookup('diffusion.repository',
                                     'callsign', callsign) or
                          fatal(f"no repository {callsign}"))
        cls.hostname = socket.gethostname()

    @classmethod
    def do(cls, cmd_name, **params):
        # Add the token & write out parameters.
        params['__conduit__'] = {'token': cls.token}
        resp = http(cls.url.netloc, f'/api/{cmd_name}', data={
            'params': json.dumps(params),
            'output': 'json',
            '__conduit__': True,
        })
        if resp['error_code'] is not None:
            raise UserError(f"conduit[{resp['error_code']}]: {resp['error_info']}")
        return resp['result']

    @classmethod
    def lookup(cls, what, key, value, attachments=[]):
        resp = cls.do(f'{what}.search',
                      constraints={f'{key}s': [value]},
                      attachments={att: True for att in attachments})
        if len(resp['data']) != 1:
            return None
        return resp['data'][0]


class Diff:
    Hunk = namedtuple('Hunk', ['old_off', 'old_len', 'new_off', 'new_len',
                               'old_eof_newline', 'new_eof_newline',
                               'added', 'deleted', 'corpus'])

    class Change:
        def __init__(self, path):
            self.old_mode = None
            self.cur_mode = None
            self.old_path = None
            self.cur_path = path
            self.away_paths = []
            self.kind = Diff.Kind.CHANGE
            self.binary = False
            self.file_type = Diff.FileType.TEXT
            self.uploads = []
            self.hunks = []

        @property
        def added(self):
            return sum(hunk.added for hunk in self.hunks)

        @property
        def deleted(self):
            return sum(hunk.deleted for hunk in self.hunks)

        def to_conduit(self, commit):
            # Record upload information
            metadata = {}
            for upload in self.uploads:
                metadata[f'{upload["type"]}:binary-phid'] = upload['phid']
                metadata[f'{upload["type"]}:file:size'] = len(upload['value'])
                metadata[f'{upload["type"]}:file:mime-type'] = upload['mime']

            # Translate hunks
            hunks = [{
                'oldOffset': hunk.old_off,
                'oldLength': hunk.old_len,
                'newOffset': hunk.new_off,
                'newLength': hunk.new_len,
                'addLines': hunk.added,
                'delLines': hunk.deleted,
                'isMissingOldNewline': not hunk.old_eof_newline,
                'isMissingNewNewline': not hunk.new_eof_newline,
                'corpus': hunk.corpus,
            } for hunk in self.hunks]

            old_props = {'unix:filemode': self.old_mode} if self.old_mode else {}
            cur_props = {'unix:filemode': self.cur_mode} if self.cur_mode else {}

            return {
                'metadata': metadata,
                'oldPath': self.old_path,
                'currentPath': self.cur_path,
                'awayPaths': self.away_paths,
                'oldProperties': old_props,
                'newProperties': cur_props,
                'commitHash': commit.hg_hash,
                'type': self.kind.value,
                'fileType': self.file_type.value,
                'hunks': hunks,
            }

    class Kind(Enum):
        ADD = 1
        CHANGE = 2
        DELETE = 3
        MOVE_AWAY = 4
        COPY_AWAY = 5
        MOVE_HERE = 6
        COPY_HERE = 7
        MULTICOPY = 8

        def short(self):
            if self == self.ADD:
                return 'A '
            elif self == self.CHANGE:
                return 'M '
            elif self == self.DELETE:
                return 'D '
            elif self == self.MOVE_AWAY:
                return 'R>'
            elif self == self.MOVE_HERE:
                return '>R'
            elif self == self.COPY_AWAY:
                return 'C>'
            elif self == self.COPY_HERE:
                return '>C'
            elif self == self.MULTICOPY:
                return 'C*'

    class FileType(Enum):
        TEXT = 1
        IMAGE = 2
        BINARY = 3
        DIRECTORY = 4 # Should never show up...
        SYMLINK = 5 # XXX(nika): Support symlinks (do we care?)?
        DELETED = 6
        NORMAL = 7

    def __init__(self, commit):
        self.commit = commit
        self.changes = {}
        self.phid = None

        raw = run('git', 'diff-tree', '-r', '--raw', '-z', '-M', '-C',
                  '--no-abbrev', commit.commit_hash)
        # Strip the prefix sha1, and remove the trailing null
        for c in raw[:-1].split('\0:')[1:]:
            self.parse_change(c)

    @property
    def added(self):
        return sum(change.added for change in self.changes.values())

    @property
    def deleted(self):
        return sum(change.deleted for change in self.changes.values())

    def change_for(self, path):
        if path not in self.changes:
            self.changes[path] = self.Change(path)
        return self.changes[path]

    def parse_change(self, raw):
        """Parse a single raw change into a Change object"""
        # `--raw -z` only uses '\0' to split paths, other sections are still
        # space-separated.
        [fields, *paths] = raw.split('\0')
        [a_mode, b_mode, a_blob, b_blob, kind_l] = fields.split(' ')

        # Figure out what paths and modes to use
        if len(paths) == 2:
            [a_path, b_path] = paths
        else:
            a_path = b_path = paths[0]
        change = self.change_for(b_path)

        # Extract the bodies of blobs to compare
        a_body, b_body = b'', b''
        if a_blob != NULL_SHA1:
            a_body = run('git', 'cat-file', 'blob', a_blob, binary=True)
        if b_blob != NULL_SHA1:
            b_body = run('git', 'cat-file', 'blob', b_blob, binary=True)

        # Detect if we're binary, and generate a unified diff
        change.binary = b'\0' in a_body or b'\0' in b_body
        if change.binary:
            a_mime = mimetypes.guess_type(a_path)[0] or ''
            b_mime = mimetypes.guess_type(b_path)[0] or ''
            change.uploads = [
                {'type': 'old', 'value': a_body, 'mime': a_mime, 'phid': None},
                {'type': 'new', 'value': b_body, 'mime': b_mime, 'phid': None},
            ]
            if a_mime.startswith('image/') or b_mime.startswith('image/'):
                change.file_type = self.FileType.IMAGE
            else:
                change.file_type = self.FileType.BINARY
        else:
            # We can only diff non-identical blobs, otherwise we'll find no
            # changes. Detect that case and produce an empty diff.
            if a_blob == b_blob:
                # Identical blobs have no diff, and thus get a fake hunk.
                lines = a_body.decode(errors='replace').splitlines(keepends=True)
                lines = [f" {l}" for l in lines]
                old_off = new_off = 1
                old_len = new_len = len(lines)
            else:
                # Use difflib to generate the base diff hunk, and match on the
                # hunk line to extract offset and length info.
                [hdr, *lines] = list(difflib.unified_diff(
                    a_body.decode(errors='replace').splitlines(keepends=True),
                    b_body.decode(errors='replace').splitlines(keepends=True),
                    n=99999999,
                ))[2:]

                m = re.match(r'@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@', hdr, re.I)
                old_off = int(m.group(1))
                old_len = int(m.group(2) or 1)
                new_off = int(m.group(3))
                new_len = int(m.group(4) or 1)

            # Collect some stats about the diff, and generate the corpus we
            # want to send to Phabricator. Python's `difflib` doesn't handle
            # missing newlines well (https://bugs.python.org/issue2142), so we
            # have to handle it manually.
            old_eof_newline = True
            new_eof_newline = True
            corpus = ''
            for line in lines:
                corpus += line
                if not line.endswith('\n'):
                    corpus += '\n\\ No newline at end of file\n'
                    if line[0] != '+':
                        old_eof_newline = False
                    if line[0] != '-':
                        new_eof_newline = False

            change.hunks = [self.Hunk(
                old_off=old_off, old_len=old_len,
                new_off=new_off, new_len=new_len,
                old_eof_newline=old_eof_newline,
                new_eof_newline=new_eof_newline,
                added=sum(1 for l in lines if l[0] == '+'),
                deleted=sum(1 for l in lines if l[0] == '-'),
                corpus=corpus,
            )]
            change.file_type = self.FileType.TEXT

        # Determine the correct kind from the letter
        if kind_l[0] == 'A':
            change.kind = self.Kind.ADD
            change.new_mode = b_mode

        elif kind_l[0] == 'D':
            change.kind = self.Kind.DELETE
            change.old_mode = a_mode
            change.old_path = a_path

        elif kind_l[0] == 'M':
            change.kind = self.Kind.CHANGE
            if a_mode != b_mode:
                change.old_mode = a_mode
                change.new_mode = b_mode
            change.old_path = a_path
            assert change.old_path == change.cur_path

        elif kind_l[0] == 'R':
            change.kind = self.Kind.MOVE_HERE
            if a_mode != b_mode:
                change.old_mode = a_mode
                change.new_mode = b_mode

            change.old_path = a_path
            old = self.change_for(change.old_path)
            if old.kind in [self.Kind.MOVE_AWAY, self.Kind.COPY_AWAY]:
                old.kind = self.Kind.MULTICOPY
            elif old.kind != self.Kind.MULTICOPY:
                old.kind = self.Kind.MOVE_AWAY
            old.away_paths.append(change.cur_path)

        elif kind_l[0] == 'C':
            change.kind = self.Kind.COPY_HERE
            if a_mode != b_mode:
                change.old_mode = a_mode
                change.new_mode = b_mode

            change.old_path = a_path
            old = self.change_for(change.old_path)
            if old.kind == self.Kind.MOVE_AWAY:
                old.kind = self.Kind.MULTICOPY
            else:
                old.kind = self.Kind.COPY_AWAY
            old.away_paths.append(change.cur_path)

        else:
            raise f"unsupported change type {kind_l[0]}"

        return change

    def do_uploads(self, style):
        for change in self.changes.values():
            for upload in change.uploads:
                print(style.bold_yellow('Uploading Binary'),
                      f"{change.cur_path} [{upload['type']}] {upload['mime']}")
                data_base64 = base64.standard_b64encode(upload['value'])
                upload['phid'] = Conduit.do('file.upload',
                                            data_base64=data_base64.decode())
                print(f"    File PHID: {upload['phid']}")

    def do_publish(self, style):
        print(style.bold_yellow('Publishing Patch'), f"{self.commit.subject}")
        changes = [change.to_conduit(self.commit)
                   for change in self.changes.values()]
        diff = Conduit.do('differential.creatediff',
                          changes=changes,
                          sourceMachine=Conduit.hostname,
                          sourceControlSystem='hg',
                          sourceControlPath='/',
                          sourceControlBaseRevision=self.commit.parent.hg_hash,
                          creationMethod='phlay',
                          lintStatus='none',
                          unitStatus='none',
                          repositoryPHID=Conduit.repository['phid'],
                          sourcePath=str(Conduit.top),
                          # XXX(nika): This seems kinda irrelevant?
                          branch='HEAD')
        print(f"    Diff URI: {diff['uri']}")

        # Add information about our local commit to the patch. This info is
        # needed by lando.
        Conduit.do('differential.setdiffproperty',
                   diff_id=diff['diffid'],
                   name='local:commits',
                   data=json.dumps({
                       self.commit.hg_hash: {
                           'author': self.commit.author_name,
                           'authorEmail': self.commit.author_email,
                           'time': int(self.commit.unix_date),
                           'summary': self.commit.subject,
                           'message': self.commit.raw_body.strip(),
                           'commit': self.commit.hg_hash,
                           'tree': self.commit.tree_hash,
                           'parents': [self.commit.parent.hg_hash],
                       }
                   }))
        return diff['phid']


class Cached:
    """single-instance cached object helper"""
    def __new__(cls, *args, **kwargs):
        if not hasattr(cls, '_cache'):
            cls._cache = {}
        key = cls.key(*args, **kwargs)
        self = cls._cache.get(key, None)
        if self is None:
            self = super().__new__(cls)
            cls._cache[key] = self
            self.init(*args, **kwargs)
        return self

    @classmethod
    def key(cls, *args):
        return tuple(map(str, args))

    def init(self):
        pass


class Revision(Cached):
    dep_re = re.compile(r'Depends\s+On\s*D([0-9]+)', re.I)

    def init(self, revid):
        self.revid = int(revid)

    @onceprop
    def info(self):
        return (Conduit.lookup('differential.revision', 'id', self.revid,
                               attachments=['reviewers']) or
                fatal(f"No such revision {self.revid}"))

    @onceprop
    def summary(self):
        return self.dep_re.sub('', self.raw_summary, count=1).strip()

    @onceprop
    def depends_on(self):
        dep = self.dep_re.match(self.raw_summary)
        return Revision(dep.group(1)) if dep else None

    @onceprop
    def phid(self):
        return self.info['phid']

    @onceprop
    def repo_phid(self):
        return self.info['fields']['repositoryPHID']

    @onceprop
    def bug(self):
        return Bug(self.info['fields']['bugzilla.bug-id'])

    @onceprop
    def title(self):
        return self.info['fields']['title']

    @onceprop
    def reviewers(self):
        infos = self.info['attachments']['reviewers']['reviewers']
        return [reviewer['reviewerPHID'] for reviewer in infos]

    @onceprop
    def raw_summary(self):
        return self.info['fields']['summary']

    @onceprop
    def url(self):
        return f"https://{Conduit.url.netloc}/D{self.revid}"


class Bug(Cached):
    _title = None

    def init(self, bugno):
        self.bugno = int(bugno)

    @onceprop
    def title(self):
        resp = http('bugzilla.mozilla.org', f'/rest/bug/{self.bugno}')
        if resp.get('error', False):
            if resp['code'] == 102:  # access error
                return '<private bug>'
            raise UserError(resp['message'])
        return resp['bugs'][0]['summary']


class Reviewer(Cached):
    def init(self, tag):
        self.tag = tag

    @onceprop
    def info(self):
        return (Conduit.lookup('user', 'username', self.tag) or
                Conduit.lookup('project', 'slug', self.tag) or
                fatal(f"no such reviewer: {self.tag}"))

    @onceprop
    def kind(self):
        return self.info['type']

    @onceprop
    def phid(self):
        return self.info['phid']

    @onceprop
    def name(self):
        if self.kind == 'USER':
            return self.info['fields']['realName']
        return self.info['fields']['name']

    @onceprop
    def handle(self):
        if self.kind == 'USER':
            return ':' + self.info['fields']['username']
        return '#' + self.tag


class Commit(Cached):
    reviewer_re = re.compile(r'r((?:[?=,][^,\s]+)+)', flags=re.I)

    # Fields pulled from 'git show'
    abbrev          = '%h'
    commit_hash     = '%H'
    tree_hash       = '%T'
    parent_hashes   = '%P'
    author_name     = '%an'
    author_email    = '%ae'
    author_date     = '%aD'
    unix_date       = '%at'
    committer_name  = '%cn'
    committer_email = '%ce'
    committer_date  = '%cD'
    subject         = '%s'
    body            = '%b'
    raw_body        = '%B'

    @classmethod
    def key(cls, rev):
        if re.fullmatch(r'[a-f0-9]{40}', rev, re.I):
            return rev  # If it looks like a full sha1, just return it
        return run('git', 'rev-parse', '--verify', rev)

    def init(self, rev):
        self.transactions = []

        # Read information from 'git show'
        FIELDS = {k: v for k, v in Commit.__dict__.items()
                  if type(v) == str and v.startswith('%')}
        FORMAT = '%x00'.join(FIELDS.values())

        info = run('git', 'show', '-q', '--format=' + FORMAT, rev)
        self.__dict__.update(zip(FIELDS.keys(), info.split('\0')))
        self.parent_hashes = self.parent_hashes.split()

        # Parse the revision out of body, and strip to store in summary.
        self.revision = None
        def rev_replace(match):
            self.revision = Revision(match.group(2))
            return ""
        self.summary = re.sub(
            r'^Differential\s+Revision:\s*(.*/)?D([0-9]+)$',
            rev_replace, self.body, count=1, flags=re.I | re.M
        ).strip()

    @onceprop
    def parent(self):
        if len(self.parent_hashes) == 1:
            return Commit(self.parent_hashes[0])
        return None

    @onceprop
    def diff(self):
        return Diff(self)

    @onceprop
    def hg_hash(self):
        try:
            hg_hash = run('git-cinnabar', 'git2hg', self.commit_hash)
            if hg_hash != NULL_SHA1:
                return hg_hash
        except FileNotFoundError:
            pass

        # NOTE: We fall-back to using our git hash if we don't have a hg one.
        # this is OK as it matches arc-cinnabar's behaviour.
        return self.commit_hash

    @onceprop
    def title(self):
        return self.reviewer_re.sub('', self.subject).strip()

    @onceprop
    def reviewers(self):
        return [Reviewer(name)
                for rmatch in self.reviewer_re.finditer(self.subject, re.I)
                for name in re.split(r'[?=,]', rmatch.group(1))[1:]]

    @onceprop
    def bug(self):
        bugmatch = re.search(r'bug\s+(\d+)', self.subject, re.I)
        return bugmatch and Bug(bugmatch.group(1))

    def add_transaction(self, type, value):
        self.transactions.append({
            'type': type,
            'value': value,
        })

    def recommit(self, parent, message):
        message = message.strip()  # Make sure to clean up trailing whitespace
        if parent == self.parent and message == self.raw_body.strip():
            return self

        # Set up the commit environment
        env = dict(os.environ)
        env.update(GIT_AUTHOR_NAME=self.author_name,
                   GIT_AUTHOR_EMAIL=self.author_email,
                   GIT_AUTHOR_DATE=self.author_date,
                   GIT_COMMITTER_NAME=self.committer_name,
                   GIT_COMMITTER_EMAIL=self.committer_email,
                   GIT_COMMITTER_DATE=self.committer_date)

        newsha = run('git', 'commit-tree',
                     '-p', parent.commit_hash, self.tree_hash,
                     input=message.encode(), env=env)
        return Commit(newsha)

    def __repr__(self):
        return f'<commit {self.abbrev} {repr(self.subject)}>'


def get_revisions(args):
    # Check our 'ref' argument
    if args.ref != 'HEAD':
        # Limit to '--heads' if no path is provided
        heads = [] if '/' in args.ref else ['--heads']
        lines = run('git', 'show-ref', *heads, args.ref).splitlines()
        if len(lines) != 1:
            raise UserError(f'Ambiguous or Unknown ref: {args.ref}')
        ref = lines[0].split()[1]
    else:
        ref = 'HEAD'

    # Determine which commits to reparent vs. push
    if '..' in args.revspec:
        start, end = args.revspec.split('..', 1)
        if len(end) == 0:
            end = 'HEAD'
        start, end = Commit(start), Commit(end)
    else:
        end = Commit(args.revspec)
        start = end.parent

    current = Commit(ref)
    reparent = []
    while current != end:
        if current is None:
            raise UserError(f'{end.abbrev} not direct ancestor of {ref}')
        reparent.append(current)
        current = current.parent
    reparent.reverse()

    push = []
    while current != start:
        if current is None:
            raise UserError(f'{start.abbrev} not direct ancestor of {end.abbrev}')
        push.append(current)
        current = current.parent
    push.reverse()

    if len(push) == 0:
        raise UserError('no commits specified')

    return start, ref, push, reparent


def process_args(args):
    style = args.color
    try:
        update_check(style)
    except Exception as e:
        print(style.red('warning'), f"checking for updates failed: {e}",
              file=sys.stderr)

    # Set up state for arguments
    Conduit.init(args.arcrc)
    start, ref, push, reparent = get_revisions(args)

    # Stash the current sha1 for |ref|
    initial_ref = Commit(ref)

    # Define a helper for printing styled & labeled information to stdout.
    def label(label, *rest):
        print('  ' + style.bold_cyan(label))
        print('    ' + ' '.join(str(s) for s in rest).replace('\n', '\n    '))

    # Validate that everything exists, and show computed info
    for idx, commit in enumerate(push):
        print()
        print(f"{style.yellow(commit.abbrev)} {commit.subject}")

        # Produce an error if no bug # was specified
        if commit.bug is None:
            raise UserError(f"no bug # specified")

        # Determine which revision we're working with
        if commit.revision is None:
            label('New Revision', Conduit.repository['fields']['name'])

            commit.add_transaction('repositoryPHID', Conduit.repository['phid'])
            commit.add_transaction('bugzilla.bug-id', str(commit.bug.bugno))
        else:
            label('Update Revision', commit.revision.url)

            if commit.revision.repo_phid != Conduit.repository['phid']:
                raise UserError('mismatched revision repository ' +
                                commit.revision.repo_phid)
            if commit.revision.bug != commit.bug:
                raise UserError('mismatched bug # ' +
                                str(commit.revision.bug.bugno))

        # Always write out basic bug info
        label(f"Bug {commit.bug.bugno}", commit.bug.title)

        # Log computed information about the patch to be pushed
        summary = ''
        longest = max(len(name) for name in commit.diff.changes)
        for path, change in commit.diff.changes.items():
            summary += f"{change.kind.short()} {path:<{longest}} "
            summary += style.bold(f"+{change.added}, -{change.deleted}\n")
        summary += style.bold(f"{len(commit.diff.changes)} files")
        summary += style.bold(f" (+{commit.diff.added}, -{commit.diff.deleted})")
        label('Changes', summary)

        # Title Updates
        if not commit.revision or commit.revision.title != commit.title:
            commit.add_transaction('title', commit.title)
            label('Set Title', commit.title)

        # Summary Updates
        oldsummary = commit.revision and commit.revision.summary
        if oldsummary != commit.summary:
            commit.add_transaction('summary', commit.summary)
            label('Set Summary', commit.summary)

        # Do some validation on dependencies
        olddepends = commit.revision and commit.revision.depends_on
        if olddepends:
            # Check for attempts to change the dependency graph
            if idx == 0:
                raise UserError(f"parent D{olddepends.revid} not in push")
            elif commit.parent.revision != olddepends:
                raise UserError(f"phlay can't change parent D{olddepends.revid}")
        elif idx > 0 and oldsummary == commit.summary:
            # Force a summary change if a dependency add is needed
            commit.add_transaction('summary', commit.summary)

        # Add any reviewers not in the original commit
        to_add = []
        for reviewer in commit.reviewers:
            if commit.revision and reviewer.phid in commit.revision.reviewers:
                continue
            to_add.append(f"blocking({reviewer.phid})")
            label('Add Reviewer', reviewer.name, f"[{reviewer.handle}]")
        if len(to_add) > 0:
            commit.add_transaction('reviewers.add', to_add)

    # Request user confirmation of printed information.
    if not args.assume_yes:
        if input(style.bold('\nProceed? (y/N) ')).lower() != 'y':
            raise UserError('user aborted')
    print()

    # Perform all uploads, and then publish all patches.
    for commit in push:
        commit.diff.do_uploads(style)
    for commit in push:
        phid = commit.diff.do_publish(style)
        commit.add_transaction('update', phid)

    # Perform the commit rewriting
    parent = start
    for idx, commit in enumerate(push):
        print(style.bold_yellow(f"Requesting Review"), f"{commit.subject}")

        # Add a 'Depends on' entry to the transaction if needed
        if idx > 0:
            for txn in commit.transactions:
                if txn['type'] == 'summary':
                    txn['value'] += f"\n\nDepends on D{parent.revision.revid}"
                    txn['value'] = txn['value'].strip()
                    break

        # Send the revision edit request.
        params = {'transactions': commit.transactions}
        if commit.revision is not None:
            params['objectIdentifier'] = commit.revision.phid
        editrv = Conduit.do('differential.revision.edit', **params)

        # Get additional information about the newly created revision
        if commit.revision is None:
            revurl = Revision(editrv['object']['id']).url
        else:
            revurl = commit.revision.url
        print(f"    Revision URI: {revurl}")

        # Perform a rewrite of the commit, and move to the next
        commitmsg = commit.raw_body.strip()
        if commit.revision is None:
            commitmsg += f"\n\nDifferential Revision: {revurl}\n"
        parent = commit.recommit(parent, commitmsg)

    # Reparent remaining commits
    for commit in reparent:
        parent = commit.recommit(parent, commit.raw_body)

    # Rewrite 'ref'
    if initial_ref != parent:
        print(style.bold_yellow(f"Updating Ref"), ref)
        print(f"    {initial_ref.abbrev} => {parent.abbrev}")
        run('git', 'update-ref', '-m', 'phlay: rewrite',
            ref, parent.commit_hash, initial_ref.commit_hash)


def update_check(style):
    data = http('raw.githubusercontent.com',
                '/mystor/phlay/master/phlay', binary=True)
    match = re.search(rb"__version__\s*=\s*'([^']+)'", data, re.I)
    new_version = match.group(1).decode() if match else '0.1.0'
    if new_version > __version__:
        changes = f"RELEASES.md#version-{new_version.replace('.', '')}"
        print(textwrap.dedent(f"""
            {style.bold_yellow("NOTE: New Version Available")}
             - phlay {__version__} => {new_version}
             - https://github.com/mystor/phlay/blob/master/{changes}
            """), file=sys.stderr)


def main():
    parser = ArgumentParser(description='phlay commits onto differential')
    parser.add_argument('--version', action='version',
                        version=f"phlay {__version__}")
    parser.add_argument('--ref', '-r', nargs=1, default='HEAD',
                        help='git ref to update after rewriting commits')
    parser.add_argument('--assume-yes', '-y', action='store_true',
                        help='disable confirmation prompts')
    parser.add_argument('--arcrc', nargs=1, default='~/.arcrc',
                        help='arc configuration file')
    parser.add_argument('--color', default='auto', type=Style,
                        choices=['always', 'never', 'auto'],
                        help='control output colorization')
    parser.add_argument('revspec', nargs='?', default='HEAD',
                        help='commit range to push for review')
    args = parser.parse_args()

    try:
        process_args(args)
    except KeyboardInterrupt:
        print(args.color.bold_red('error'), 'interrupted', file=sys.stderr)
        sys.exit(1)
    except subprocess.CalledProcessError as e:
        pretty = ' '.join(shlex.quote(c) for c in e.cmd)
        print(args.color.bold_red('error'), f"command failed: {pretty}",
              file=sys.stderr)
    except (UserError, FileNotFoundError) as e:
        print(args.color.bold_red('error'), e, file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()
