#!/usr/bin/env python3

__version__ = '0.1.9'

import sys
import os
import re
import json
import curses
import base64
import socket
import difflib
import mimetypes
import textwrap
import shlex

from http.client import HTTPSConnection, HTTPException
from urllib.parse import urlencode, urlparse
from subprocess import check_output, check_call, CalledProcessError
from argparse import ArgumentParser
from tempfile import TemporaryDirectory
from collections import namedtuple
from pathlib import Path
from enum import Enum


NULL_SHA1 = '0' * 40
EMPTY_BLOB = 'e69de29bb2d1d6434b8b29ae775ad8c2e48c5391'


class Style:
    """ANSI color helper"""

    class Wrap(str):
        def __call__(self, s):
            if self == '':
                return str(s)
            return self + str(s) + curses.tparm(curses.tigetstr('sgr0')).decode()

    def __init__(self, color, stream=sys.stdout):
        dumb = os.environ.get("TERM") == "dumb"
        self.styled = color == 'always' or (color == 'auto' and stream.isatty() and not dumb)
        if self.styled:
            curses.setupterm()
            self._setf = curses.tigetstr('setaf') or curses.tigetstr('setf')

    def __getattr__(self, name):
        if not self.styled:
            return self.Wrap('')
        if '_' in name:
            return self.Wrap(''.join(getattr(self, n) for n in name.split('_')))
        call = [curses.tigetstr(name)]
        if name in 'black blue cyan green magenta red white yellow'.split():
            call = [self._setf, getattr(curses, 'COLOR_' + name.upper())]
        return self.Wrap(curses.tparm(*call).decode())


class UserError(Exception):
    pass


class Conduit:
    def __init__(self, arcrc_path):
        # Load the global and local Arcanist configuration
        git_top = (check_output(['git', 'rev-parse', '--show-toplevel'])
                   .decode().strip())
        if git_top.startswith('/'):
            self.top = Path(git_top)
        else:
            # This is probably a Windows path.
            # If we're in WSL, this needs to be converted.
            try:
                self.top = Path(check_output(['/bin/wslpath', git_top]).decode()
                                .strip())
            except FileNotFoundError:
                # Probably not in WSL.
                self.top = Path(git_top)
        with open(self.top / '.arcconfig') as f:
            arcconfig = json.load(f)

        # Load the URL from the local arcconfig
        self.url = urlparse(arcconfig['phabricator.uri'])
        if self.url.scheme != 'https':
            raise UserError('Only HTTPS scheme phabricator.uri are supported')

        # Find our authentication token
        arcrc_path = Path(arcrc_path).expanduser()
        arcrc = {}
        try:
            with open(arcrc_path) as f:
                arcrc = json.load(f)

            self.token = next(data['token'] for url, data in arcrc['hosts'].items()
                              if urlparse(url).netloc == self.url.netloc)
        except (IOError, StopIteration):
            self.token = input(textwrap.dedent(f"""\
                LOGIN TO PHABRICATOR

                Open this page in your browser, and login if necessary:
                https://{self.url.netloc}/conduit/login

                API Token from that page: """)).strip()

            # Double-check the token works
            self.do('user.whoami')

            # Update our arcrc
            api_uri = f"https://{self.url.netloc}/api/"
            arcrc['hosts'] = arcrc.get('hosts', {})
            arcrc['hosts'][api_uri] = arcrc['hosts'].get(api_uri, {})
            arcrc['hosts'][api_uri]['token'] = self.token
            with open(arcrc_path, 'w') as f:
                json.dump(arcrc, f, indent=2)

        # Connect to Conduit to determine our repository's PHID
        self.repository = self.search_one('diffusion.repository', {
            'callsigns': [arcconfig['repository.callsign']]
        })
        self.hostname = socket.gethostname()

    def do(self, cmd_name, **params):
        # Add the token & write out parameters.
        params['__conduit__'] = { 'token': self.token }
        body = urlencode({
            'params': json.dumps(params),
            'output': 'json',
            '__conduit__': True,
        })

        # Send the POST request
        conn = HTTPSConnection(self.url.netloc)
        conn.request("POST", f'/api/{cmd_name}', body=body)

        # Read the response as JSON
        resp = json.load(conn.getresponse())
        if resp['error_code'] is not None:
            raise UserError(f"conduit[{resp['error_code']}]: {resp['error_info']}")
        return resp['result']

    def search_one(self, what, constraints, attachments={}):
        resp = self.do(f'{what}.search',
                       constraints=constraints,
                       attachments=attachments,
                       limit=1)
        if len(resp['data']) != 1:
            raise UserError(f'cannot find {what} (constraints={constraints})')
        return resp['data'][0]


class Diff:
    Hunk = namedtuple('Hunk', ['old_off', 'old_len', 'new_off', 'new_len',
                               'old_eof_newline', 'new_eof_newline',
                               'added', 'deleted', 'corpus'])

    class Change:
        def __init__(self, path):
            self.old_mode = None
            self.cur_mode = None
            self.old_path = None
            self.cur_path = path
            self.away_paths = []
            self.kind = Diff.Kind.CHANGE
            self.binary = False
            self.file_type = Diff.FileType.TEXT
            self.uploads = []
            self.hunks = []

        @property
        def added(self):
            return sum(hunk.added for hunk in self.hunks)

        @property
        def deleted(self):
            return sum(hunk.deleted for hunk in self.hunks)

        def to_conduit(self, commit):
            # Record upload information
            metadata = {}
            for upload in self.uploads:
                metadata[f'{upload["type"]}:binary-phid'] = upload['phid']
                metadata[f'{upload["type"]}:file:size'] = len(upload['value'])
                metadata[f'{upload["type"]}:file:mime-type'] = upload['mime']

            # Translate hunks
            hunks = [{
                'oldOffset': hunk.old_off,
                'oldLength': hunk.old_len,
                'newOffset': hunk.new_off,
                'newLength': hunk.new_len,
                'addLines': hunk.added,
                'delLines': hunk.deleted,
                'isMissingOldNewline': not hunk.old_eof_newline,
                'isMissingNewNewline': not hunk.new_eof_newline,
                'corpus': hunk.corpus,
            } for hunk in self.hunks]

            old_props = {'unix:filemode': self.old_mode} if self.old_mode else {}
            cur_props = {'unix:filemode': self.cur_mode} if self.cur_mode else {}

            return {
                'metadata': metadata,
                'oldPath': self.old_path,
                'currentPath': self.cur_path,
                'awayPaths': self.away_paths,
                'oldProperties': old_props,
                'newProperties': cur_props,
                'commitHash': commit.hg_hash,
                'type': self.kind.value,
                'fileType': self.file_type.value,
                'hunks': hunks,
            }

    class Kind(Enum):
        ADD = 1
        CHANGE = 2
        DELETE = 3
        MOVE_AWAY = 4
        COPY_AWAY = 5
        MOVE_HERE = 6
        COPY_HERE = 7
        MULTICOPY = 8

        def short(self):
            if self == self.ADD:
                return 'A '
            elif self == self.CHANGE:
                return 'M '
            elif self == self.DELETE:
                return 'D '
            elif self == self.MOVE_AWAY:
                return 'R>'
            elif self == self.MOVE_HERE:
                return '>R'
            elif self == self.COPY_AWAY:
                return 'C>'
            elif self == self.COPY_HERE:
                return '>C'
            elif self == self.MULTICOPY:
                return 'C*'


    class FileType(Enum):
        TEXT = 1
        IMAGE = 2
        BINARY = 3
        DIRECTORY = 4 # Should never show up...
        SYMLINK = 5 # XXX(nika): Support symlinks (do we care?)?
        DELETED = 6
        NORMAL = 7

    def __init__(self, commit):
        self.commit = commit
        self.changes = {}
        self.phid = None

        raw = check_output(['git', 'diff-tree', '-r', '--raw', '-z', '-M', '-C',
                            '--no-abbrev', commit.commit_hash]).decode(errors='replace')
        # Strip the prefix sha1, and remove the trailing null
        for c in raw[:-1].split('\0:')[1:]:
            self.parse_change(c)

    @property
    def added(self):
        return sum(change.added for change in self.changes.values())

    @property
    def deleted(self):
        return sum(change.deleted for change in self.changes.values())

    def change_for(self, path):
        if path not in self.changes:
            self.changes[path] = self.Change(path)
        return self.changes[path]

    def parse_change(self, raw):
        """Parse a single raw change into a Change object"""
        # `--raw -z` only uses '\0' to split paths, other sections are still
        # space-separated.
        [fields, *paths] = raw.split('\0')
        [a_mode, b_mode, a_blob, b_blob, kind_l] = fields.split(' ')

        # Figure out what paths and modes to use
        if len(paths) == 2:
            [a_path, b_path] = paths
        else:
            a_path = b_path = paths[0]
        change = self.change_for(b_path)

        # Extract the bodies of blobs to compare
        if a_blob == NULL_SHA1:
            a_blob, a_body = EMPTY_BLOB, b''
        else:
            a_body = check_output(['git', 'cat-file', 'blob', a_blob])

        if b_blob == NULL_SHA1:
            b_blob, b_body = EMPTY_BLOB, b''
        else:
            b_body = check_output(['git', 'cat-file', 'blob', b_blob])

        # Detect if we're binary, and generate a unified diff
        change.binary = b'\0' in a_body or b'\0' in b_body
        if change.binary:
            a_mime = mimetypes.guess_type(a_path)[0] or ''
            b_mime = mimetypes.guess_type(b_path)[0] or ''
            change.uploads = [
                {'type': 'old', 'value': a_body, 'mime': a_mime, 'phid': None},
                {'type': 'new', 'value': b_body, 'mime': b_mime, 'phid': None},
            ]
            if a_mime.startswith('image/') or b_mime.startswith('image/'):
                change.file_type = self.FileType.IMAGE
            else:
                change.file_type = self.FileType.BINARY
        else:
            # We can only diff non-identical blobs, otherwise we'll find no
            # changes. Detect that case and produce an empty diff.
            if a_blob == b_blob:
                # Identical blobs have no diff, and thus get a fake hunk.
                lines = a_body.decode(errors='replace').splitlines(keepends=True)
                lines = [f" {l}" for l in lines]
                old_off = new_off = 1
                old_len = new_len = len(lines)
            else:
                # Use difflib to generate the base diff hunk, and match on the
                # hunk line to extract offset and length info.
                [hdr, *lines] = list(difflib.unified_diff(
                    a_body.decode(errors='replace').splitlines(keepends=True),
                    b_body.decode(errors='replace').splitlines(keepends=True),
                    n=99999999,
                ))[2:]

                m = re.match(r'@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@', hdr, re.I)
                old_off = int(m.group(1))
                old_len = int(m.group(2) or 1)
                new_off = int(m.group(3))
                new_len = int(m.group(4) or 1)

            # Collect some stats about the diff, and generate the corpus we
            # want to send to Phabricator. Python's `difflib` doesn't handle
            # missing newlines well (https://bugs.python.org/issue2142), so we
            # have to handle it manually.
            old_eof_newline = True
            new_eof_newline = True
            corpus = ''
            for line in lines:
                corpus += line
                if not line.endswith('\n'):
                    corpus += '\n\\ No newline at end of file\n'
                    if line[0] != '+':
                        old_eof_newline = False
                    if line[0] != '-':
                        new_eof_newline = False

            change.hunks = [self.Hunk(
                old_off=old_off, old_len=old_len,
                new_off=new_off, new_len=new_len,
                old_eof_newline=old_eof_newline,
                new_eof_newline=new_eof_newline,
                added=sum(1 for l in lines if l[0] == '+'),
                deleted=sum(1 for l in lines if l[0] == '-'),
                corpus=corpus,
            )]
            change.file_type = self.FileType.TEXT

        # Determine the correct kind from the letter
        if kind_l[0] == 'A':
            change.kind = self.Kind.ADD
            change.cur_mode = b_mode

        elif kind_l[0] == 'D':
            change.kind = self.Kind.DELETE
            change.old_mode = a_mode
            change.old_path = a_path

        elif kind_l[0] == 'M':
            change.kind = self.Kind.CHANGE
            if a_mode != b_mode:
                change.old_mode = a_mode
                change.cur_mode = b_mode
            change.old_path = a_path
            assert change.old_path == change.cur_path

        elif kind_l[0] == 'R':
            change.kind = self.Kind.MOVE_HERE
            if a_mode != b_mode:
                change.old_mode = a_mode
                change.cur_mode = b_mode

            change.old_path = a_path
            old = self.change_for(change.old_path)
            if old.kind in [self.Kind.MOVE_AWAY, self.Kind.COPY_AWAY]:
                old.kind = self.Kind.MULTICOPY
            elif old.kind != self.Kind.MULTICOPY:
                old.kind = self.Kind.MOVE_AWAY
            old.away_paths.append(change.cur_path)

        elif kind_l[0] == 'C':
            change.kind = self.Kind.COPY_HERE
            if a_mode != b_mode:
                change.old_mode = a_mode
                change.cur_mode = b_mode

            change.old_path = a_path
            old = self.change_for(change.old_path)
            if old.kind == self.Kind.MOVE_AWAY:
                old.kind = self.Kind.MULTICOPY
            else:
                old.kind = self.Kind.COPY_AWAY
            old.away_paths.append(change.cur_path)

        else:
            raise f"unsupported change type {kind_l[0]}"

        return change

    def do_uploads(self, style, conduit):
        for change in self.changes.values():
            for upload in change.uploads:
                print(style.bold_yellow('Uploading Binary'),
                      f"{change.cur_path} [{upload['type']}] {upload['mime']}")
                data_base64 = base64.standard_b64encode(upload['value'])
                upload['phid'] = conduit.do('file.upload',
                                            data_base64=data_base64.decode())
                print(f"    File PHID: {upload['phid']}")

    def do_publish(self, style, conduit):
        print(style.bold_yellow('Publishing Patch'), f"{self.commit.subject}")
        changes = [change.to_conduit(self.commit)
                   for change in self.changes.values()]
        diff = conduit.do('differential.creatediff',
                          changes=changes,
                          sourceMachine=conduit.hostname,
                          sourceControlSystem='hg',
                          sourceControlPath='/',
                          sourceControlBaseRevision=self.commit.parent().hg_hash,
                          creationMethod='phlay',
                          lintStatus='none',
                          unitStatus='none',
                          repositoryPHID=conduit.repository['phid'],
                          sourcePath=str(conduit.top),
                          # XXX(nika): This seems kinda irrelevant?
                          branch='HEAD')
        print(f"    Diff URI: {diff['uri']}")

        # Add information about our local commit to the patch. This info is
        # needed by lando.
        conduit.do('differential.setdiffproperty',
                   diff_id=diff['diffid'],
                   name='local:commits',
                   data=json.dumps({
                       self.commit.hg_hash: {
                           'author': self.commit.author_name,
                           'authorEmail': self.commit.author_email,
                           'time': int(self.commit.unix_date),
                           'summary': self.commit.subject,
                           'message': self.commit.raw_body.strip(),
                           'commit': self.commit.hg_hash,
                           'tree': self.commit.tree_hash,
                           'parents': [self.commit.parent().hg_hash],
                       }
                   }))
        return diff['phid']


class Cached:
    """single-instance cached object helper"""
    def __new__(cls, *args, **kwargs):
        if not hasattr(cls, '_cache'):
            cls._cache = {}
        key = cls.key(*args, **kwargs)
        self = cls._cache.get(key, None)
        if self is None:
            self = super().__new__(cls)
            cls._cache[key] = self
            self.init(*args, **kwargs)
        return self

    @classmethod
    def key(cls, *args):
        return tuple(map(str, args))

    def init(self):
        pass


class Revision(Cached):
    _info = None
    DEP_SPEC = re.compile(r'Depends\s+On\s*D([0-9]+)', re.I)

    def init(self, revid):
        self.revid = int(revid)

    def info(self, conduit):
        if self._info is None:
            self._info = conduit.search_one('differential.revision', {
                'ids': [self.revid]
            }, attachments={'reviewers': True})
        return self._info

    def summary(self, conduit):
        return self.DEP_SPEC.sub(
            '', self.info(conduit)['fields']['summary'], count=1
        ).strip()

    def edges(self, conduit):
        info = self.info(conduit)
        self._edges = conduit.do('edge.search',
                                 sourcePHIDs=[info['phid']],
                                 types=['revision.parent'],
                                 limit=900)['data']
        return [edge['destinationPHID'] for edge in self._edges]

    def url(self, conduit):
        return f"https://{conduit.url.netloc}/D{self.revid}"


class Bug(Cached):
    _info = None

    def init(self, bugno):
        self.bugno = int(bugno)

    def info(self, _conduit):
        if self._info is None:
            conn = HTTPSConnection('bugzilla.mozilla.org')
            conn.request('GET', f"/rest/bug/{self.bugno}")
            resp = json.load(conn.getresponse())
            if resp.get('error', False):
                if resp['code'] != 102:  # Not an access error
                    raise UserError(resp['message'])
                self._info = {'summary': '<private bug>'}
            else:
                self._info = resp['bugs'][0]
        return self._info


class Reviewer(Cached):
    _info = None

    def init(self, tag):
        self.tag = tag

    def info(self, conduit):
        if self._info is None:
            try:
                # First, we try to locate a user with the reviewer's name.
                self._info = conduit.search_one('user', {
                    'usernames': [self.tag]
                })
            except UserError:
                try:
                    # Then we locate a project based on its slug.
                    self._info = conduit.search_one('project', {
                        'slugs': [self.tag]
                    })
                except UserError:
                    raise UserError(f"no such reviewer: {self.tag}")

        return self._info


class Commit(Cached):
    # Fields pulled from 'git show'
    abbrev          = '%h'
    commit_hash     = '%H'
    tree_hash       = '%T'
    parent_hashes   = '%P'
    author_name     = '%an'
    author_email    = '%ae'
    author_date     = '%aD'
    unix_date       = '%at'
    committer_name  = '%cn'
    committer_email = '%ce'
    committer_date  = '%cD'
    subject         = '%s'
    body            = '%b'
    raw_body        = '%B'

    @classmethod
    def key(cls, rev):
        if re.fullmatch(r'[a-f0-9]{40}', rev, re.I):
            return rev  # If it looks like a full sha1, just return it
        return check_output(['git', 'rev-parse', '--verify', rev]).decode().strip()

    def init(self, rev):
        self.transactions = []
        self._diff = None

        # Read information from 'git show'
        FIELDS = { k: v for k, v in Commit.__dict__.items()
                   if type(v) == str and v.startswith('%') }
        FORMAT = '%x00'.join(FIELDS.values())

        info = check_output(['git', 'show', '-q', f'--format={FORMAT}', rev])
        self.__dict__.update(zip(FIELDS.keys(), info.decode(errors='replace').split('\0')))
        self.parent_hashes = self.parent_hashes.split()

        # Compute more info based on the commit message etc.
        bugmatch = re.search(r'bug\s+(\d+)', self.subject, re.I)
        self.bug = bugmatch and Bug(bugmatch.group(1))

        # Parse the reviewer list
        reviewer_re = r'r((?:[?=,][^,\s]+)+)'
        self.reviewers = []
        for rmatch in re.finditer(reviewer_re, self.subject, re.I):
            for name in re.split(r'[?=,]', rmatch.group(1))[1:]:
                self.reviewers.append(Reviewer(name))

        # Parse the revision out of body, and strip to store in summary.
        self.revision = None
        def rev_replace(match):
            self.revision = Revision(match.group(2))
            return ""
        self.summary = re.sub(
            r'^Differential\s+Revision:\s*(.*/)?D([0-9]+)$',
            rev_replace, self.body, count=1, flags=re.I | re.M
        ).strip()

        self.title = re.sub(reviewer_re, '', self.subject, flags=re.I).strip()

        # Check if this commit has a corresponding mercurial hash already
        # computed and cached.
        try:
            self.hg_hash = check_output([
                'git-cinnabar', 'git2hg', self.commit_hash
            ]).decode().strip()

            # If we don't have a valid cinnabar hash, fall-back. If
            # '--hg-bundle' is passed, this will be corrected before pushing.
            if self.hg_hash == NULL_SHA1:
                self.hg_hash = self.commit_hash
        except FileNotFoundError:
            # Handle git-cinnabar being uninstalled
            self.hg_hash = self.commit_hash


    def parent(self):
        if len(self.parent_hashes) == 1:
            return Commit(self.parent_hashes[0])
        return None

    def diff(self):
        if not self._diff:
            self._diff = Diff(self)
        return self._diff

    def add_transaction(self, type, value):
        self.transactions.append({
            'type': type,
            'value': value,
        })

    def recommit(self, parent, message):
        message = message.strip()  # Make sure to clean up trailing whitespace
        if parent == self.parent() and message == self.raw_body.strip():
            return self

        # Set up the commit environment
        env = dict(os.environ)
        env.update(GIT_AUTHOR_NAME=self.author_name,
                   GIT_AUTHOR_EMAIL=self.author_email,
                   GIT_AUTHOR_DATE=self.author_date,
                   GIT_COMMITTER_NAME=self.committer_name,
                   GIT_COMMITTER_EMAIL=self.committer_email,
                   GIT_COMMITTER_DATE=self.committer_date)

        newsha = check_output([
            'git', 'commit-tree',
            '-p', parent.commit_hash,
            self.tree_hash
        ], input=message.encode(), env=env).decode().strip()
        return Commit(newsha)

    def __repr__(self):
        return f'<commit {self.abbrev} {repr(self.subject)}>'


def get_revisions(args):
    # Check our 'ref' argument
    if args.ref != 'HEAD':
        # Limit to '--heads' if no path is provided
        heads = [] if '/' in args.ref else ['--heads']
        lines = check_output(['git', 'show-ref', *heads, args.ref]) \
            .decode().strip().splitlines()
        if len(lines) != 1:
            raise UserError(f'Ambiguous or Unknown ref: {args.ref}')
        ref = lines[0].split()[1]
    else:
        ref = 'HEAD'

    # Determine which commits to reparent vs. push
    if '..' in args.revspec:
        start, end = args.revspec.split('..', 1)
        if len(end) == 0:
            end = 'HEAD'
        start, end = Commit(start), Commit(end)
    else:
        end = Commit(args.revspec)
        start = end.parent()

    current = Commit(ref)
    reparent = []
    while current != end:
        if current is None:
            raise UserError(f'{end.abbrev} not direct ancestor of {ref}')
        reparent.append(current)
        current = current.parent()
    reparent.reverse()

    push = []
    while current != start:
        if current is None:
            raise UserError(f'{start.abbrev} not direct ancestor of {end.abbrev}')
        push.append(current)
        current = current.parent()
    push.reverse()

    if len(push) == 0:
        raise UserError('no commits specified')

    return start, ref, push, reparent


def process_args(args):
    style = args.color
    try:
        update_check(style)
    except Exception as e:
        print(style.red('warning'), f"checking for updates failed: {e}",
              file=sys.stderr)

    # Set up state for arguments
    conduit = Conduit(args.arcrc)
    start, ref, push, reparent = get_revisions(args)

    # Stash the current sha1 for |ref|
    initial_ref = Commit(ref)

    # Define a helper for printing styled & labeled information to stdout.
    def label(label, *rest):
        print('  ' + style.bold_cyan(label))
        print('    ' + ' '.join(str(s) for s in rest).replace('\n', '\n    '))

    # Validate that everything exists, and show computed info
    for idx, commit in enumerate(push):
        print()
        print(f"{style.yellow(commit.abbrev)} {commit.subject}")

        # Produce an error if no bug # was specified
        if commit.bug is None:
            raise UserError(f"no bug # specified")

        # Determine which revision we're working with
        if commit.revision is None:
            label('New Revision', conduit.repository['fields']['name'])

            commit.add_transaction('repositoryPHID', conduit.repository['phid'])
            commit.add_transaction('bugzilla.bug-id', str(commit.bug.bugno))
        else:
            revinfo = commit.revision.info(conduit)
            revfields = revinfo['fields']

            action = 'Update Revision'
            if args.reopen and revfields['status']['closed']:
                commit.add_transaction('reopen', True)
                action = 'Reopen Revision'
            label(action, commit.revision.url(conduit))

            if revfields['repositoryPHID'] != conduit.repository['phid']:
                raise UserError('mismatched revision repository ' +
                                revfields['repositoryPHID'])
            if revfields['bugzilla.bug-id'] != str(commit.bug.bugno):
                raise UserError('mismatched bug # ' +
                                revfields['bugzilla.bug-id'])

        # Always write out basic bug info
        try:
            buginfo = commit.bug.info(conduit)
            label(f"Bug {commit.bug.bugno}", buginfo['summary'])
        except HTTPException as err:
            label(f"Bug {commit.bug.bugno}", style.red(f"<HTTP error> {err}"))

        # Log computed information about the patch to be pushed
        diff = commit.diff()
        summary = ''
        longest = max(len(name) for name in diff.changes)
        for path, change in diff.changes.items():
            summary += f"{change.kind.short()} {path:<{longest}} "
            summary += style.bold(f"+{change.added}, -{change.deleted}\n")
        summary += style.bold(f"{len(diff.changes)} files")
        summary += style.bold(f" (+{diff.added}, -{diff.deleted})")
        label('Changes', summary)

        # Title Updates
        if not commit.revision or revinfo['fields']['title'] != commit.title:
            commit.add_transaction('title', commit.title)
            label('Set Title', commit.title)

        # Summary Updates
        oldsummary = commit.revision and commit.revision.summary(conduit)
        if oldsummary != commit.summary:
            commit.add_transaction('summary', commit.summary)
            label('Set Summary', commit.summary)

        # Add any reviewers not in the original commit
        to_add = []
        rev_phids = []
        if commit.revision:
            reviewers = revinfo['attachments']['reviewers']['reviewers']
            rev_phids = [reviewer['reviewerPHID'] for reviewer in reviewers]

        for reviewer in commit.reviewers:
            reviewerinfo = reviewer.info(conduit)
            if reviewerinfo['phid'] not in rev_phids:
                to_add.append(f"blocking({reviewerinfo['phid']})")
                if reviewerinfo['type'] == 'USER':
                    label('Add Reviewer',
                          reviewerinfo['fields']['realName'],
                          f"[:{reviewerinfo['fields']['username']}]")
                elif reviewerinfo['type'] == 'PROJ':
                    label('Add Reviewer',
                          reviewerinfo['fields']['name'],
                          f"[#{reviewer.tag}]")
        if len(to_add) > 0:
            commit.add_transaction('reviewers.add', to_add)

    # Request user confirmation of printed information.
    if not args.assume_yes:
        if input(style.bold('\nProceed? (y/N) ')).lower() != 'y':
            raise UserError('user aborted')
    print()

    # Perform all uploads, and then publish all patches.
    for commit in push:
        commit.diff().do_uploads(style, conduit)
    for commit in push:
        phid = commit.diff().do_publish(style, conduit)
        commit.add_transaction('update', phid)

    # Perform the commit rewriting
    parent = start
    for idx, commit in enumerate(push):
        print(style.bold_yellow(f"Requesting Review"), f"{commit.subject}")

        # Update dependency relationships if needed.
        pphids = [] if idx == 0 else [parent.revision.info(conduit)['phid']]
        if commit.revision is None or pphids != commit.revision.edges(conduit):
            commit.add_transaction('parents.set', pphids)

        # Send the revision edit request.
        params = {'transactions': commit.transactions}
        if commit.revision is not None:
            params['objectIdentifier'] = commit.revision.info(conduit)['phid']
        editrv = conduit.do('differential.revision.edit', **params)

        # Get additional information about the newly created revision
        if commit.revision is None:
            revurl = Revision(editrv['object']['id']).url(conduit)
        else:
            revurl = commit.revision.url(conduit)
        print(f"    Revision URI: {revurl}")

        # Perform a rewrite of the commit, and move to the next
        commitmsg = commit.raw_body.strip()
        if commit.revision is None:
            commitmsg += f"\n\nDifferential Revision: {revurl}"
        parent = commit.recommit(parent, commitmsg)

    # Reparent remaining commits
    for commit in reparent:
        parent = commit.recommit(parent, commit.raw_body)

    # Rewrite 'ref'
    if initial_ref != parent:
        print(style.bold_yellow(f"Updating Ref"), ref)
        print(f"    {initial_ref.abbrev} => {parent.abbrev}")
        check_call([
            'git', 'update-ref', '-m', 'phlay: rewrite',
            ref, parent.commit_hash, initial_ref.commit_hash,
        ])


def update_check(style):
    conn = HTTPSConnection('raw.githubusercontent.com')
    conn.request('GET', '/mystor/phlay/master/phlay')
    resp = conn.getresponse().read().decode()
    match = re.search(r"__version__\s*=\s*'([^']+)'", resp, re.I)
    new_version = match.group(1) if match else '0.1.0'
    if new_version > __version__:
        changes = f"RELEASES.md#version-{new_version.replace('.', '')}"
        print(textwrap.dedent(f"""
            {style.bold_yellow("NOTE: New Version Available")}
             - phlay {__version__} => {new_version}
             - https://github.com/mystor/phlay/blob/master/{changes}
            """), file=sys.stderr)


def main():
    parser = ArgumentParser(description='phlay commits onto differential')
    parser.add_argument('--version', action='version',
                        version=f"phlay {__version__}")
    parser.add_argument('--ref', '-r', nargs=1, default='HEAD',
                        help='git ref to update after rewriting commits')
    parser.add_argument('--assume-yes', '-y', action='store_true',
                        help='disable confirmation prompts')
    parser.add_argument('--arcrc', nargs=1, default='~/.arcrc',
                        help='arc configuration file')
    parser.add_argument('--color', default='auto', type=Style,
                        choices=['always', 'never', 'auto'],
                        help='control output colorization')
    parser.add_argument('--reopen', action='store_true',
                        help='re-open closed revisions')
    parser.add_argument('revspec', nargs='?', default='HEAD',
                        help='commit range to push for review')
    args = parser.parse_args()

    try:
        process_args(args)
    except KeyboardInterrupt:
        print(args.color.bold_red('error'), 'interrupted', file=sys.stderr)
        sys.exit(1)
    except CalledProcessError as e:
        pretty = ' '.join(shlex.quote(c) for c in e.cmd)
        print(args.color.bold_red('error'), f"command failed: {pretty}",
              file=sys.stderr)
    except (UserError, FileNotFoundError) as e:
        print(args.color.bold_red('error'), e, file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()
